import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import re

# Configuration
NOTION_TOKEN = "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"
NOTION_DATABASE_ID = "21e3342b-9620-8050-89a4-d66f5e59441b"
OLLAMA_URL = "http://localhost:11434"
OLLAMA_MODEL = "gemma3:latest"

# Liste dynamique des mots-cl√©s utilis√©s pendant l'ex√©cution
existing_keywords = set()

# -------- Extraction des articles avec r√©sum√© du site --------
def extract_articles(url):
    response = requests.get(url)
    response.raise_for_status()
    soup = BeautifulSoup(response.content, 'html.parser')
    articles = []

    for article in soup.select('article.mt-3'):
        a_tag = article.find('a', class_='font-bold')
        title = ""
        if a_tag:
            h3 = a_tag.find('h3')
            if h3:
                title = h3.get_text(strip=True)

        if not title or len(title) <= 5:
            continue

        summary = ""
        summary_div = article.find('div', class_='newsletter-html')
        if summary_div:
            paragraphs = summary_div.find_all('p')
            summary = "\n\n".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))
            if not summary:
                summary = summary_div.get_text(strip=True)

        articles.append({
            "title": title,
            "summary": summary
        })

    return articles

# -------- V√©rification Ollama --------
def is_ollama_available():
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=3)
        response.raise_for_status()
        return True
    except:
        print("‚ö†Ô∏è Ollama non disponible, mode fallback activ√©.")
        return False

# -------- Connexion √† l'IA via Ollama --------
def query_ollama(prompt):
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False},
            timeout=30
        )
        response.raise_for_status()
        return response.json().get("response", "").strip()
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur Ollama : {e}")
        return None

# -------- R√©sum√© IA --------
def summarize_article(summary):
    prompt = f"""Texte original :
{summary}

Ta t√¢che : Fournir directement un r√©sum√© concis de 2 √† 3 lignes. 
R√©ponds uniquement avec le r√©sum√©. Ne fais pas d‚Äôintroduction ni de conclusion :"""
    
    result = query_ollama(prompt)
    return result if result else "R√©sum√© IA indisponible"

# -------- G√©n√©ration des mots-cl√©s --------
def generate_keywords(summary_ia):
    prompt = f"""Voici un r√©sum√© : {summary_ia}

Donne trois mots-cl√©s courts et pertinents s√©par√©s par une virgule, sans explication :"""
    result = query_ollama(prompt)
    if not result:
        return []

    # Nettoyage basique des mots-cl√©s
    keywords = [kw.strip().lower() for kw in result.split(',') if kw.strip()]
    return keywords

# -------- Gestion des cat√©gories dynamiques --------
def get_or_add_keywords(keywords):
    final_keywords = []
    for kw in keywords:
        if kw.lower() in existing_keywords:
            final_keywords.append(kw)
        else:
            existing_keywords.add(kw.lower())
            final_keywords.append(kw)
    return final_keywords

# -------- Extraction de la date depuis l'URL --------
def extract_date_from_url(url):
    match = re.search(r"\b(\d{4}-\d{2}-\d{2})\b", url)
    if match:
        return match.group(1)
    else:
        return datetime.now().strftime("%Y-%m-%d")

# -------- Envoi vers Notion --------
def send_to_notion(title, summary, summary_ia, keywords, source_url, publication_date):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    payload = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "Titre": {"title": [{"text": {"content": title[:200]}}]},
            "R√©sum√©": {"rich_text": [{"text": {"content": summary[:2000]}}]},
            "R√©sum√© IA": {"rich_text": [{"text": {"content": summary_ia[:2000]}}]},
            "Cat√©gorie(s) IA": {"multi_select": [{"name": kw} for kw in keywords]},
            "URL": {"url": source_url},
            "Date de parution": {"date": {"start": publication_date}}
        }
    }

    response = requests.post("https://api.notion.com/v1/pages", headers=headers, json=payload)
    if response.status_code in (200, 201):
        print(f"‚úÖ Envoy√© √† Notion : {title[:50]}...")
    else:
        print(f"‚ùå Erreur Notion : {response.status_code} - {response.text}")

# -------- Pipeline complet --------
def process_articles(url):
    ollama_available = is_ollama_available()
    publication_date = extract_date_from_url(url)

    articles = extract_articles(url)
    print(f"\nüì∞ {len(articles)} articles trouv√©s.\n")

    for idx, article in enumerate(articles, 1):
        title = article["title"]
        summary = article["summary"]
        print(f"{idx}. {title}")

        try:
            if not summary:
                summary = "R√©sum√© indisponible"

            summary_ia = summarize_article(summary)
            keywords_generated = generate_keywords(summary_ia)
            keywords_to_use = get_or_add_keywords(keywords_generated)

            print(f"   üìÑ R√©sum√© site : {summary}")
            print(f"   üìë R√©sum√© IA : {summary_ia}")
            print(f"   üè∑Ô∏è Mots-cl√©s : {keywords_to_use}")

            send_to_notion(title, summary, summary_ia, keywords_to_use, url, publication_date)

            time.sleep(1)

        except Exception as e:
            print(f"‚ùå Erreur traitement : {e}")
            continue

if __name__ == "__main__":
    target_url = "https://tldr.tech/marketing/2025-06-27"  # Change selon besoin
    process_articles(target_url)
