import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import re
from gtts import gTTS  
import os

# Configuration
NOTION_TOKEN = "Notion_token_ici"  # Remplace par ton token Notion
NOTION_DATABASE_ID = "Notion_ID_ici"  # Remplace par l'ID de ta base de donn√©es Notion
OLLAMA_URL = "http://localhost:11434"
OLLAMA_MODEL = "model_ollama_ici"  # Remplace par le mod√®le Ollama que tu utilises

# Dossier pour sauvegarder les fichiers audio
AUDIO_DIR = "audio_files"
os.makedirs(AUDIO_DIR, exist_ok=True)

# Liste dynamique des mots-cl√©s utilis√©s pendant l'ex√©cution
existing_keywords = set()

# -------- Extraction des articles avec r√©sum√© du site --------
def extract_articles(url):
    response = requests.get(url)
    response.raise_for_status()
    soup = BeautifulSoup(response.content, 'html.parser')
    articles = []

    for article in soup.select('article.mt-3'):
        a_tag = article.find('a', class_='font-bold')
        title = ""
        if a_tag:
            h3 = a_tag.find('h3')
            if h3:
                title = h3.get_text(strip=True)

        if not title or len(title) <= 5:
            continue

        summary = ""
        summary_div = article.find('div', class_='newsletter-html')
        if summary_div:
            paragraphs = summary_div.find_all('p')
            summary = "\n\n".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))
            if not summary:
                summary = summary_div.get_text(strip=True)

        articles.append({
            "title": title,
            "summary": summary
        })

    return articles

# -------- V√©rification Ollama --------
def is_ollama_available():
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=3)
        response.raise_for_status()
        return True
    except:
        print("‚ö†Ô∏è Ollama non disponible, mode fallback activ√©.")
        return False

# -------- Connexion √† l'IA via Ollama --------
def query_ollama(prompt):
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False},
            timeout=30
        )
        response.raise_for_status()
        return response.json().get("response", "").strip()
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur Ollama : {e}")
        return None

# -------- R√©sum√© IA --------
def summarize_article(summary):
    prompt = f"""Texte original :
{summary}

Ta t√¢che : Fournir directement un r√©sum√© concis de 2 √† 3 lignes en fran√ßais. 
R√©ponds uniquement avec le r√©sum√©. Ne fais pas d'introduction ni de conclusion :"""
    
    result = query_ollama(prompt)
    return result if result else "R√©sum√© IA indisponible"

# -------- G√©n√©ration des mots-cl√©s --------
def generate_keywords(summary_ia):
    prompt = f"""Voici un r√©sum√© : {summary_ia}

En anglais, donne trois mots-cl√©s courts et pertinents s√©par√©s par une virgule, sans explication :"""
    result = query_ollama(prompt)
    if not result:
        return []

    keywords = [kw.strip() for kw in result.split(',') if kw.strip()]
    return keywords

# -------- Gestion des cat√©gories dynamiques --------
def get_or_add_keywords(keywords):
    final_keywords = []
    for kw in keywords:
        if kw.lower() in existing_keywords:
            final_keywords.append(kw)
        else:
            existing_keywords.add(kw.lower())
            final_keywords.append(kw)
    return final_keywords

# -------- Extraction de la date depuis l'URL --------
def extract_date_from_url(url):
    match = re.search(r"\b(\d{4}-\d{2}-\d{2})\b", url)
    if match:
        return match.group(1)
    else:
        return datetime.now().strftime("%Y-%m-%d")

# -------- Extraction de la cat√©gorie depuis l'URL --------
def extract_category_from_url(url):
    match = re.search(r"https?://[^/]+/([^/]+)/\d{4}-\d{2}-\d{2}", url)
    if match:
        return match.group(1)
    return "default"

# -------- G√©n√©ration audio avec gTTS --------
def generate_audio(text, filename):
    try:
        tts = gTTS(text=text, lang='fr')
        tts.save(filename)
        print(f"üîä Audio g√©n√©r√© : {filename}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration audio : {e}")
        return False

# -------- G√©n√©ration audio combin√© directement --------
def generate_combined_audio(combined_text, output_filename):
    try:
        # Ajouter des pauses entre les articles avec des points de suspension
        formatted_text = combined_text.replace(". Article ", "... Article ")
        
        tts = gTTS(text=formatted_text, lang='fr', slow=False)
        tts.save(output_filename)
        print(f"üéµ Audio combin√© g√©n√©r√© : {output_filename}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration audio combin√© : {e}")
        return False

# -------- Envoi de l'audio combin√© vers Notion --------
def send_combined_to_notion(title, summary, full_text, keywords, source_url, publication_date, audio_local_path):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    payload = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "Titre": {"title": [{"text": {"content": title[:200]}}]},
            "R√©sum√©": {"rich_text": [{"text": {"content": summary[:2000]}}]},
            "R√©sum√© IA": {"rich_text": [{"text": {"content": full_text[:2000]}}]},
            "Cat√©gorie(s) IA": {"multi_select": [{"name": kw} for kw in keywords]},
            "URL": {"url": source_url},
            "Date de parution": {"date": {"start": publication_date}},
            "Audio R√©sum√©": {"rich_text": [{"text": {"content": audio_local_path}}]}
        }
    }

    response = requests.post("https://api.notion.com/v1/pages", headers=headers, json=payload)
    if response.status_code in (200, 201):
        print(f"‚úÖ Audio combin√© envoy√© √† Notion : {title[:50]}...")
    else:
        print(f"‚ùå Erreur Notion (combin√©) : {response.status_code} - {response.text}")

# -------- Envoi vers Notion --------
def send_to_notion(title, summary, summary_ia, keywords, source_url, publication_date, audio_local_path):
    headers = {
        "Authorization": f"Bearer {NOTION_TOKEN}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28"
    }

    payload = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "Titre": {"title": [{"text": {"content": title[:200]}}]},
            "R√©sum√©": {"rich_text": [{"text": {"content": summary[:2000]}}]},
            "R√©sum√© IA": {"rich_text": [{"text": {"content": summary_ia[:2000]}}]},
            "Cat√©gorie(s) IA": {"multi_select": [{"name": kw} for kw in keywords]},
            "URL": {"url": source_url},
            "Date de parution": {"date": {"start": publication_date}},
            "Audio R√©sum√©": {"rich_text": [{"text": {"content": audio_local_path}}]}
        }
    }

    response = requests.post("https://api.notion.com/v1/pages", headers=headers, json=payload)
    if response.status_code in (200, 201):
        print(f"‚úÖ Envoy√© √† Notion : {title[:50]}...")
    else:
        print(f"‚ùå Erreur Notion : {response.status_code} - {response.text}")

# -------- Pipeline complet --------
def process_articles(url):
    ollama_available = is_ollama_available()
    publication_date = extract_date_from_url(url)
    category = extract_category_from_url(url)

    articles = extract_articles(url)
    print(f"\nüì∞ {len(articles)} articles trouv√©s.\n")

    # Liste pour stocker les fichiers audio individuels (optionnel)
    individual_audio_files = []
    
    # Texte combin√© pour l'audio final
    combined_text_parts = []

    for idx, article in enumerate(articles, 1):
        title = article["title"]
        summary = article["summary"]
        print(f"{idx}. {title}")

        try:
            if not summary:
                summary = "R√©sum√© indisponible"

            summary_ia = summarize_article(summary)
            keywords_generated = generate_keywords(summary_ia)
            keywords_to_use = get_or_add_keywords(keywords_generated)

            print(f"   üìÑ R√©sum√© site : {summary}")
            print(f"   üìë R√©sum√© IA : {summary_ia}")
            print(f"   üè∑Ô∏è Mots-cl√©s : {keywords_to_use}")

            # Cr√©ation du texte pour l'audio avec le format demand√©
            audio_text = f"Article {idx} du {category}. {summary_ia}"
            combined_text_parts.append(audio_text)

            # G√©n√©ration de l'audio individuel
            audio_filename = os.path.join(AUDIO_DIR, f"article_{idx}_{category}.mp3")
            if generate_audio(audio_text, audio_filename):
                individual_audio_files.append(audio_filename)

            send_to_notion(title, summary, summary_ia, keywords_to_use, url, publication_date, audio_filename)

            time.sleep(1)

        except Exception as e:
            print(f"‚ùå Erreur traitement : {e}")
            continue

    # G√©n√©ration de l'audio combin√©
    if combined_text_parts:
        # Cr√©ation du texte complet avec s√©parateurs naturels
        full_combined_text = " ".join(combined_text_parts)
        
        # G√©n√©ration de l'audio combin√© unique
        combined_audio_filename = os.path.join(AUDIO_DIR, f"combined_{category}_{publication_date}.mp3")
        if generate_combined_audio(full_combined_text, combined_audio_filename):
            print(f"‚úÖ Audio combin√© cr√©√© : {combined_audio_filename}")
            
            # Envoyer l'audio combin√© √† Notion comme entr√©e s√©par√©e
            send_combined_to_notion(f"R√©sum√© Audio {category.title()} - {publication_date}", 
                                  f"Audio combin√© de {len(articles)} articles du {category}", 
                                  full_combined_text, 
                                  [category], 
                                  url, 
                                  publication_date, 
                                  combined_audio_filename)
        

if __name__ == "__main__":
    target_url = "https://tldr.tech/marketing/2025-06-27"  # Modifie l'URL selon besoin
    process_articles(target_url)